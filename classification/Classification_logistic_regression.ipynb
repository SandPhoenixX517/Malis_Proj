{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "from skimage import io, transform, img_as_float\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_size = 32\n",
    "num_classes = 2\n",
    "BATCH_SIZE = 100\n",
    "learning_rate = 0.001\n",
    "transformation = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, number_images, root_dir, folder, label_file , transforma=None):\n",
    "        # Number of images to be loaded.\n",
    "        self.number_images = number_images\n",
    "        with open(root_dir+label_file, 'r') as file:\n",
    "            lines=file.read().splitlines()\n",
    "        self.Names_labels = []\n",
    "        for element in lines:\n",
    "            self.Names_labels.append(element.split(' '))\n",
    "        \n",
    "        # Here I construct the path to the images\n",
    "        self.root_dir = root_dir+folder\n",
    "        # this is to collect the transform, if I supply any.\n",
    "        self.transforma = transforma\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.number_images\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img_name = os.path.join(self.root_dir,self.Names_labels[idx][0].split('/')[-1])\n",
    "        image = io.imread(img_name)\n",
    "        resized_img = transform.resize(image, (28, 28))\n",
    "        sample = img_as_float(resized_img)\n",
    "        target = int(float(self.Names_labels[idx][1]))\n",
    "\n",
    "        if self.transforma:\n",
    "            sample = self.transforma(sample)\n",
    "        \n",
    "        return [sample.float(), target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path_train =\".\"\n",
    "number_images_training = 6966 \n",
    "train_dataset = Dataset(number_images=number_images_training, root_dir=Path_train, folder = '/train',\n",
    "                        label_file = '/COWC_train_list_detection.txt', transforma = transformation)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "Path_test = \".\"\n",
    "number_images_testing = 2050\n",
    "test_dataset = Dataset(number_images=number_images_testing, root_dir=Path_test, folder= '/test',\n",
    "                       label_file = '/COWC_test_list_detection.txt', transforma = transformation)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the Normal Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2352 , num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_hat = self.linear(x)\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.875478982925415\n",
      "46.26075518131256\n",
      "45.87075090408325\n",
      "45.60809004306793\n",
      "45.37194103002548\n",
      "45.2206848859787\n",
      "45.11464446783066\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(2352, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(7):\n",
    "    loss_total = 0\n",
    "    for i, (images, labels) in enumerate(train_dataloader):  \n",
    "        images = images.view(images.size(0), -1).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "        optimizer.zero_grad()  \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)  \n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        loss_total = loss_total + loss.item()\n",
    "    print(loss_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_dataloader:\n",
    "    labels = labels.to(device)\n",
    "    images = images.view(images.size(0), -1).to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 48.09756088256836%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {}%'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the Logistic regression with a non-linear activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression_Sigmoid(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2352 , num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_hat = F.sigmoid(self.linear(x))\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.46171897649765\n",
      "46.81635820865631\n",
      "46.7336688041687\n",
      "46.67952758073807\n",
      "46.67915105819702\n",
      "46.6350993514061\n",
      "46.601563811302185\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression_Sigmoid(2352, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(7):\n",
    "    loss_total = 0\n",
    "    for i, (images, labels) in enumerate(train_dataloader):  \n",
    "        images = images.view(images.size(0), -1).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "        optimizer.zero_grad()  \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)  \n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        loss_total = loss_total + loss.item()\n",
    "    print(loss_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_dataloader:\n",
    "    labels = labels.to(device)\n",
    "    images = images.view(images.size(0), -1).to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 47.17073059082031%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {}%'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
